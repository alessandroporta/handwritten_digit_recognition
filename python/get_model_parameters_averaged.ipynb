{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d212c2c5-414d-4627-812a-68bce5454b6d",
   "metadata": {
    "id": "d212c2c5-414d-4627-812a-68bce5454b6d",
    "outputId": "8b119197-af1e-4bdc-89b5-83a310da60f8"
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'torch' has no attribute 'load'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 6\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Load the model parameters from the .pth file\u001b[39;00m\n\u001b[0;32m      5\u001b[0m model_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./results/model_averaged.pth\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m----> 6\u001b[0m model_state_dict \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m(model_path, map_location\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# Initialize global max and min\u001b[39;00m\n\u001b[0;32m      9\u001b[0m global_max \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39mnp\u001b[38;5;241m.\u001b[39minf\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'torch' has no attribute 'load'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "# Load the model parameters from the .pth file\n",
    "model_path = \"./results/model_averaged.pth\"\n",
    "model_state_dict = torch.load(model_path, map_location=torch.device('cpu'))\n",
    "\n",
    "# Initialize global max and min\n",
    "global_max = -np.inf\n",
    "global_min = np.inf\n",
    "\n",
    "# First pass: Find global max and min\n",
    "for param in model_state_dict.values():\n",
    "    param_np = param.cpu().numpy()\n",
    "    param_max = np.max(param_np)\n",
    "    param_min = np.min(param_np)\n",
    "\n",
    "    # Update global max and min\n",
    "    global_max = max(global_max, param_max)\n",
    "    global_min = min(global_min, param_min)\n",
    "\n",
    "# Define rescaling and rounding function\n",
    "def rescale_and_round(value, min_val, max_val, new_min=-128, new_max=127):\n",
    "    scaled_value = ((value - min_val) / (max_val - min_val)) * (new_max - new_min) + new_min\n",
    "    return np.round(scaled_value).astype(int)  # Round to nearest integer and cast to int\n",
    "\n",
    "def decimal_to_signed_binary(value):\n",
    "\n",
    "    # If the value is negative, calculate two's complement\n",
    "    if value < 0:\n",
    "        value = (1 << 8) + value  # Two's complement for negative values\n",
    "\n",
    "    # Format as an 8-bit binary string\n",
    "    return f\"{value:08b}\"\n",
    "\n",
    "# Specify output file for saving scaled weights and biases\n",
    "output_file = \"./results/model_parameters_scaled_averaged.txt\"\n",
    "\n",
    "# Second pass: Write rescaled parameters to file\n",
    "with open(output_file, \"w\") as f:\n",
    "\n",
    "    f.write(f\"Global Max: {global_max:.8f}\\n\")\n",
    "    f.write(f\"Global Min: {global_min:.8f}\\n\")\n",
    "\n",
    "    for name, param in model_state_dict.items():\n",
    "        # Convert the tensor to a NumPy array\n",
    "        param_np = param.cpu().numpy()\n",
    "\n",
    "        # Rescale parameters\n",
    "        scaled_param_np = rescale_and_round(param_np, global_min, global_max)\n",
    "\n",
    "        val_binary = decimal_to_signed_binary(val)\n",
    "\n",
    "        # Write name as 'name = [...]'\n",
    "        f.write(f\"{name} = [\\n{{\\n\")\n",
    "\n",
    "        # Write shape and global max/min values\n",
    "        f.write(f\"  Shape: {param_np.shape}\\n\")\n",
    "\n",
    "        # Write rescaled weights/biases\n",
    "        f.write(\"  Scaled Weights/Biases:\\n\")\n",
    "\n",
    "        # Check if the parameter is a matrix (2D) or vector (1D) and format accordingly\n",
    "        if scaled_param_np.ndim == 2:  # Matrix case\n",
    "            for row in scaled_param_np:\n",
    "                formatted_row = \", \".join(f\"8'sb{val_binary}\" for val in row) + \",\"  # Format each value with comma\n",
    "                f.write(f\"    {formatted_row}\\n\")\n",
    "        elif scaled_param_np.ndim == 1:  # Vector case\n",
    "            formatted_vector = \", \".join(f\"8'sb{val_binary}\" for val in scaled_param_np) + \",\"  # Format each value with comma\n",
    "            f.write(f\"    {formatted_vector}\\n\")\n",
    "        else:\n",
    "            f.write(f\"    {scaled_param_np}\\n\")\n",
    "\n",
    "        # Close the block with braces\n",
    "        f.write(\"}\\n]\\n\\n\")\n",
    "\n",
    "print(f\"Model parameters have been scaled and saved to {output_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a8c50e0-f861-417a-b57d-5ed89823eb5a",
   "metadata": {
    "id": "9a8c50e0-f861-417a-b57d-5ed89823eb5a"
   },
   "outputs": [],
   "source": [
    "!pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4c84b84-8fc6-47ba-9044-2b436f310231",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
